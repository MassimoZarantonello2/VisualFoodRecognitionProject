{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv('ground_truth/train_small.csv', header=None)\n",
    "gt.columns = ['image', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image_path, num_augmentations=5):\n",
    "    \"\"\"\n",
    "    Esegue data augmentation su un'immagine.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Percorso dell'immagine di input.\n",
    "        num_augmentations (int): Numero di immagini augmentate da generare.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista di immagini augmentate (in formato PIL).\n",
    "    \"\"\"\n",
    "    # Trasformazioni per data augmentation\n",
    "    augmentation_transforms = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Flip orizzontale casuale\n",
    "        transforms.RandomRotation(degrees=30),   # Rotazione casuale di ±30°\n",
    "        transforms.RandomResizedCrop(size=(244, 244), scale=(0.8, 1.0)),  # Crop casuale\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variazione di colore\n",
    "    ])\n",
    "\n",
    "    # Caricamento dell'immagine originale\n",
    "    original_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Genera immagini augmentate\n",
    "    augmented_images = [augmentation_transforms(original_image) for _ in range(num_augmentations)]\n",
    "\n",
    "    return augmented_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5020/5020 [02:43<00:00, 30.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m augment_image(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_set/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mi)\n\u001b[1;32m      4\u001b[0m     train_image\u001b[38;5;241m.\u001b[39mappend(imgs)\n\u001b[0;32m----> 6\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m244\u001b[39m, \u001b[38;5;241m244\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "for i in tqdm(gt['image']):\n",
    "    imgs = augment_image('train_set/'+i)\n",
    "    train_image.append(imgs)\n",
    "\n",
    "x_train = np.array(train_image)\n",
    "x_train = x_train.reshape(-1, 244, 244, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(image_labels):\n",
    "    one_hot_encoded_labels = []\n",
    "    for label in image_labels:\n",
    "        y = np.zeros(251)\n",
    "        y[int(label)] = 1\n",
    "        one_hot_encoded_labels.append(y)\n",
    "    one_hot_encoded_labels = np.array(one_hot_encoded_labels)\n",
    "    return one_hot_encoded_labels\n",
    "\n",
    "image_labels = gt['label']\n",
    "y_train = one_hot_encoding(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (244, 244, 3), num_classes: 251\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train[0].shape\n",
    "num_classes = len(gt['label'].unique())\n",
    "print(f'input_shape: {input_shape}, num_classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (5020, 244, 244, 3), y_train.shape: (5020, 251)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train.shape: {x_train.shape}, y_train.shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova predizione con ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/massimo/Documents/visual_information_and_processing/progettoVisual/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/massimo/Documents/visual_information_and_processing/progettoVisual/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "num_classes = 251\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "# Preprocess x_train\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2)  # (5020, 3, 244, 244)\n",
    "\n",
    "# Convert y_train from one-hot to scalar labels\n",
    "y_train = torch.argmax(torch.tensor(y_train, dtype=torch.float32), dim=1)  # (5020,)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 5.7168\n",
      "Epoch [2/5], Loss: 5.3369\n",
      "Epoch [3/5], Loss: 5.0363\n",
      "Epoch [4/5], Loss: 4.7877\n",
      "Epoch [5/5], Loss: 4.5723\n",
      "Training completato!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova predizione con modello classico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_loss(history):\n",
    "  x_plot = list(range(1,len(history.history[\"loss\"])+1))\n",
    "  plt.figure()\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.plot(x_plot, history.history['loss'])\n",
    "  plt.plot(x_plot, history.history['val_loss'])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "  plt.ylim(0, 1)\n",
    "\n",
    "def plot_accuracy(history):\n",
    "  x_plot = list(range(1,len(history.history[\"accuracy\"])+1))\n",
    "  plt.figure()\n",
    "  plt.title(\"Accuracy\")\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.plot(x_plot, history.history['accuracy'])\n",
    "  plt.plot(x_plot, history.history['val_accuracy'])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "  plt.ylim(0, 1)\n",
    "\n",
    "def display_error_examples(real_images, true_label, predicted_label):\n",
    "  n_images = 4\n",
    "  i = 1\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for j in range(len(true_label)):\n",
    "      if true_label[j].argmax(axis=-1) != predicted_label[j]:\n",
    "          plt.subplot(n_images, 2, i)\n",
    "          i += 1\n",
    "          real_image = real_images[j].reshape(28, 39)\n",
    "          plt.title(f' Real: {true_label[j].argmax(axis=-1)} Predicted: {predicted_label[j]}')\n",
    "          plt.imshow(real_image, cmap='gray')\n",
    "          plt.axis('off')\n",
    "          if i > 2 * n_images:\n",
    "              break\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dei vari modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = pd.read_csv('ground_truth/val_info.csv', header=None)\n",
    "test_gt.columns = ['image', 'label']\n",
    "test_gt = test_gt.iloc[:502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 244, 244, 3)\n"
     ]
    }
   ],
   "source": [
    "test_image = []\n",
    "for image in test_gt['image']:\n",
    "    img = Image.open('val_set/'+image)\n",
    "    img = transform_image(img)\n",
    "    test_image.append(img)\n",
    "\n",
    "x_test = np.array(test_image)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 251)\n"
     ]
    }
   ],
   "source": [
    "test_image_labels = test_gt['label']\n",
    "y_test = one_hot_encoding(test_image_labels)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy sul modello easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.0062 - loss: 51.4084\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy su ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 4.38%\n"
     ]
    }
   ],
   "source": [
    "# Preprocess x_test\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, C, H, W)\n",
    "\n",
    "# Convert y_test from one-hot to scalar labels\n",
    "y_test = torch.argmax(torch.tensor(y_test, dtype=torch.float32), dim=1)  # (N,)\n",
    "\n",
    "# Create DataLoader for test data\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
